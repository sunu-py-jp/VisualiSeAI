import { GalleryItem } from "@/types";

export const galleryItems: GalleryItem[] = [
  {
    id: 1,
    title: "LLM",
    description: "Large Language Models — テキスト生成・理解の基盤となる大規模言語モデル",
    category: "Foundation",
    gradient: "from-violet-500 to-purple-700",
    emoji: "🧠",
    tags: ["NLP", "Foundation Model", "Text Generation"],
    height: "lg",
    detail:
      "Large Language Models（LLM）は、膨大なテキストデータで学習された大規模なニューラルネットワークです。GPT、Claude、LLaMAなどが代表例で、文章生成、翻訳、要約、コード生成など多様なタスクに対応します。数十億〜数兆のパラメータを持ち、Transformerアーキテクチャをベースに、次のトークンを予測する自己回帰的な学習を行います。",
  },
  {
    id: 2,
    title: "Diffusion Models",
    description: "ノイズから画像を段階的に生成する拡散モデル",
    category: "Generation",
    gradient: "from-pink-500 to-rose-600",
    emoji: "🎨",
    tags: ["Image Generation", "Denoising", "Generative"],
    height: "md",
    detail:
      "Diffusion Modelsは、データにノイズを徐々に加えるプロセスを逆転させることで、高品質な画像を生成するモデルです。DDPM、Score-based Modelsなどの理論に基づき、Stable DiffusionやDALL-E 3に応用されています。GANと比較して学習が安定しており、多様性の高い出力が得られます。",
  },
  {
    id: 3,
    title: "Transformer Architecture",
    description: "Self-Attentionベースの革命的アーキテクチャ",
    category: "Architecture",
    gradient: "from-cyan-400 to-blue-600",
    emoji: "⚡",
    tags: ["Attention", "Architecture", "2017"],
    height: "xl",
    detail:
      "Transformer（2017年「Attention Is All You Need」で提案）は、Self-Attention機構により入力系列の全要素間の関係を並列に計算できるアーキテクチャです。RNNの逐次処理の制約を克服し、GPUでの高速学習を可能にしました。現在のLLM、Vision Transformer、音声認識など、AIの基盤技術となっています。",
  },
  {
    id: 4,
    title: "RAG",
    description: "外部知識検索で回答精度を向上させるRetrieval-Augmented Generation",
    category: "Application",
    gradient: "from-emerald-400 to-teal-600",
    emoji: "🔍",
    tags: ["Retrieval", "Knowledge", "Grounding"],
    height: "lg",
    detail:
      "Retrieval-Augmented Generation（RAG）は、LLMの回答生成時に外部データベースから関連情報を検索・取得し、その情報をプロンプトに組み込む手法です。ハルシネーション（幻覚）を抑制し、最新情報や専門知識に基づいた正確な回答を生成できます。ベクトルDBとの組み合わせが一般的です。",
  },
  {
    id: 5,
    title: "Fine-tuning",
    description: "事前学習モデルをタスク特化させるファインチューニング",
    category: "Training",
    gradient: "from-amber-400 to-orange-600",
    emoji: "🔧",
    tags: ["Transfer Learning", "Adaptation", "SFT"],
    height: "md",
    detail:
      "Fine-tuningは、大規模な事前学習済みモデルを特定のタスクやドメインに適応させる手法です。全パラメータを更新するFull Fine-tuningの他、LoRAやQLoRAなどのパラメータ効率的手法が登場し、少ないリソースでの適応が可能になりました。SFT（Supervised Fine-Tuning）はRLHFの前段階としても重要です。",
  },
  {
    id: 6,
    title: "Prompt Engineering",
    description: "AIの出力を最適化するプロンプト設計技術",
    category: "Application",
    gradient: "from-lime-400 to-green-600",
    emoji: "✍️",
    tags: ["Prompting", "Few-shot", "Optimization"],
    height: "sm",
    detail:
      "Prompt Engineeringは、AIモデルに与える指示（プロンプト）を工夫することで、望ましい出力を得る技術です。Zero-shot、Few-shot、Chain-of-Thought、Role Playingなどの手法があり、モデルの重みを変更せずに性能を改善できます。",
  },
  {
    id: 7,
    title: "AI Agents",
    description: "自律的にタスクを計画・実行するAIエージェント",
    category: "Application",
    gradient: "from-indigo-500 to-violet-700",
    emoji: "🤖",
    tags: ["Autonomous", "Tool Use", "Planning"],
    height: "xl",
    detail:
      "AI Agentsは、LLMを中核として外部ツールの利用、計画立案、タスク分解、自律的な実行を行うシステムです。ReAct、AutoGPT、LangChain Agentsなどのフレームワークがあり、ウェブ検索、コード実行、API呼び出しなどを組み合わせて複雑なタスクを解決します。",
  },
  {
    id: 8,
    title: "Multimodal AI",
    description: "テキスト・画像・音声を統合的に理解するマルチモーダルAI",
    category: "Foundation",
    gradient: "from-fuchsia-500 to-pink-600",
    emoji: "👁️",
    tags: ["Vision", "Audio", "Cross-modal"],
    height: "lg",
    detail:
      "Multimodal AIは、テキスト、画像、音声、動画など複数のモダリティを統合的に処理するAIです。GPT-4V、Gemini、Claude 3のように画像理解能力を持つLLMや、テキストから画像/動画を生成するモデルが代表例です。CLIP、Flamingo、LLaVAなどのアーキテクチャが基盤技術となっています。",
  },
  {
    id: 9,
    title: "RLHF",
    description: "人間のフィードバックによる強化学習でAIを改善",
    category: "Training",
    gradient: "from-red-500 to-rose-700",
    emoji: "👥",
    tags: ["Alignment", "Reward Model", "PPO"],
    height: "md",
    detail:
      "RLHF（Reinforcement Learning from Human Feedback）は、人間の選好データを用いて報酬モデルを学習し、強化学習でLLMを最適化する手法です。ChatGPTの成功の鍵となった技術で、モデルの出力を人間の意図に沿ったものにします。DPO（Direct Preference Optimization）などの改良手法も登場しています。",
  },
  {
    id: 10,
    title: "LoRA",
    description: "低ランク適応による効率的なモデルカスタマイズ",
    category: "Training",
    gradient: "from-sky-400 to-cyan-600",
    emoji: "🔗",
    tags: ["PEFT", "Low-rank", "Efficient"],
    height: "sm",
    detail:
      "LoRA（Low-Rank Adaptation）は、大規模モデルの重み行列に低ランクの更新行列を追加することで、少ないパラメータで効率的にファインチューニングを行う手法です。元のモデルの重みは固定したまま、追加パラメータのみ学習するため、メモリ使用量を大幅に削減できます。QLoRA、DoRAなどの発展形もあります。",
  },
  {
    id: 11,
    title: "Attention Mechanism",
    description: "入力の重要部分に焦点を当てる注意機構",
    category: "Architecture",
    gradient: "from-yellow-400 to-amber-600",
    emoji: "🎯",
    tags: ["Self-Attention", "Cross-Attention", "KV Cache"],
    height: "lg",
    detail:
      "Attention Mechanismは、入力系列の各要素が他の要素にどれだけ「注意」を払うかを学習する機構です。Query、Key、Valueの3つの変換を用いて重み付き和を計算します。Multi-Head Attention、Flash Attention、Grouped Query Attentionなど多くの改良が提案されています。",
  },
  {
    id: 12,
    title: "Stable Diffusion",
    description: "オープンソースで広まった潜在拡散モデル",
    category: "Generation",
    gradient: "from-purple-500 to-indigo-700",
    emoji: "🖼️",
    tags: ["Latent Diffusion", "Open Source", "ComfyUI"],
    height: "md",
    detail:
      "Stable Diffusionは、Stability AIが公開した潜在拡散モデルです。画像を低次元の潜在空間で処理することで、高品質な画像生成を一般的なGPUで実行可能にしました。テキストからの画像生成、画像編集、ControlNetによる制御など、幅広い応用が可能で、オープンソースコミュニティにより急速に発展しています。",
  },
  {
    id: 13,
    title: "GPT Architecture",
    description: "Decoder-onlyのAutoregressive Language Model",
    category: "Architecture",
    gradient: "from-teal-400 to-emerald-600",
    emoji: "📐",
    tags: ["Decoder-only", "Autoregressive", "OpenAI"],
    height: "sm",
    detail:
      "GPT（Generative Pre-trained Transformer）は、TransformerのDecoder部分のみを使用した自己回帰型言語モデルです。次のトークンを逐次予測する方式で、GPT-1から4oまで、スケーリング則に従って性能が向上してきました。現在のLLMの主流アーキテクチャの一つです。",
  },
  {
    id: 14,
    title: "Image Generation",
    description: "テキストや条件から画像を自動生成する技術",
    category: "Generation",
    gradient: "from-orange-400 to-red-600",
    emoji: "🌅",
    tags: ["Text-to-Image", "Inpainting", "ControlNet"],
    height: "lg",
    detail:
      "Image Generationは、テキストプロンプトやスケッチなどの条件から画像を生成する技術の総称です。Diffusion Models、GAN、VAEなどのアプローチがあり、DALL-E、Midjourney、Stable Diffusion、Flux等のサービスが普及しています。ControlNet、IP-Adapterなどの制御技術も発展しています。",
  },
  {
    id: 15,
    title: "Vector Databases",
    description: "高次元ベクトルの類似度検索に特化したデータベース",
    category: "Application",
    gradient: "from-blue-500 to-indigo-600",
    emoji: "📊",
    tags: ["Embeddings", "Similarity Search", "ANN"],
    height: "md",
    detail:
      "Vector Databasesは、テキストや画像をEmbedding（ベクトル表現）に変換し、類似度検索を高速に行うための専用データベースです。Pinecone、Weaviate、Qdrant、ChromaDB、pgvectorなどが代表的で、RAGシステムの知識ストアとして不可欠な存在です。HNSW、IVFなどのインデックス手法を活用します。",
  },
  {
    id: 16,
    title: "Tokenization",
    description: "テキストをモデルが処理可能な単位に分割する技術",
    category: "Foundation",
    gradient: "from-stone-400 to-zinc-600",
    emoji: "🔤",
    tags: ["BPE", "SentencePiece", "Vocabulary"],
    height: "sm",
    detail:
      "Tokenizationは、入力テキストをモデルが処理できるトークン（サブワード単位）に分割する前処理技術です。BPE（Byte Pair Encoding）、WordPiece、SentencePieceなどのアルゴリズムがあり、語彙サイズと表現力のバランスが性能に大きく影響します。日本語などの非ラテン文字の効率的なトークン化も重要な課題です。",
  },
  {
    id: 17,
    title: "Chain-of-Thought",
    description: "段階的な推論でLLMの思考力を引き出す手法",
    category: "Application",
    gradient: "from-violet-400 to-fuchsia-600",
    emoji: "💭",
    tags: ["Reasoning", "Step-by-step", "CoT"],
    height: "lg",
    detail:
      "Chain-of-Thought（CoT）は、LLMに段階的な推論プロセスを明示させることで、複雑な問題解決能力を向上させる手法です。「Let's think step by step」のようなプロンプトや、推論例の提示により、数学問題や論理的推論の正答率が大幅に向上します。Tree-of-Thought、Graph-of-Thoughtなどの発展形もあります。",
  },
  {
    id: 18,
    title: "Model Distillation",
    description: "大きなモデルの知識を小さなモデルに転移する蒸留",
    category: "Training",
    gradient: "from-cyan-500 to-teal-700",
    emoji: "🧪",
    tags: ["Compression", "Teacher-Student", "Efficiency"],
    height: "md",
    detail:
      "Model Distillation（知識蒸留）は、大規模なTeacherモデルの出力分布を、小規模なStudentモデルに学習させることで、知識を転移する手法です。モデルのサイズを大幅に圧縮しながら性能を維持でき、エッジデバイスへのデプロイやコスト削減に貢献します。",
  },
  {
    id: 19,
    title: "Text-to-Video",
    description: "テキストから動画を自動生成する最新技術",
    category: "Generation",
    gradient: "from-rose-500 to-pink-700",
    emoji: "🎬",
    tags: ["Video Generation", "Temporal", "Sora"],
    height: "xl",
    detail:
      "Text-to-Videoは、テキストプロンプトから動画を生成する技術です。Sora、Runway Gen-3、Pika、Klingなどのモデルが登場し、映像制作の革新が進んでいます。時間的な一貫性の維持、物理法則の理解、長時間動画の生成などが主要な技術的課題です。DiTベースのアーキテクチャが主流になりつつあります。",
  },
  {
    id: 20,
    title: "Mixture of Experts",
    description: "条件に応じてエキスパートを選択的に活性化するアーキテクチャ",
    category: "Architecture",
    gradient: "from-green-500 to-emerald-700",
    emoji: "🏗️",
    tags: ["MoE", "Sparse", "Gating"],
    height: "md",
    detail:
      "Mixture of Experts（MoE）は、複数のエキスパート（専門的なサブネットワーク）からゲーティング機構で一部のみを選択的に活性化するアーキテクチャです。Mixtral、GPT-4（推定）、Switch Transformerなどで採用され、パラメータ数を増やしながら計算コストを抑制できます。スパース活性化により、効率的なスケーリングを実現します。",
  },
];

export const categories: Array<import("@/types").Category> = [
  "All",
  "Foundation",
  "Architecture",
  "Training",
  "Generation",
  "Application",
];
